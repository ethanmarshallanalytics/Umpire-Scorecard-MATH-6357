text(dffits(df_best_model), labels=rownames(df_best), cex=0.9, font=2)
title("DFFITS")
#DFBETAS
dfbetas(df_best_model)
plot(dfbetas(df_best_model),type = "o")
text(dfbetas(df_best_model), labels=rownames(df_best), cex=0.9, font=2)
title("DFBETAS")
vif(df_interaction)
round(vif(df_interaction))
plot(resid(df_interaction) ~ fitted(df_interaction))
abline(h=0)
qqnorm(resid(df_interaction))
qqline(resid(df_interaction))
plot(resid(df_interaction) ~ fitted(df_interaction))
abline(h=0)
# ------------ Model Diagnostics ---------------
plot(resid(df_best_model) ~ fitted(df_best_model))
abline(h=0)
plot(resid(df_interaction)
plot(resid(df_interaction))
plot(resid(df_interaction))
plot(resid(df_best_model))
plot(resid(df_best_model)~fitted(df_best_model))
plot(resid(df_interaction)~fitted(df_interaction))
#### WLS#####
### blood presser vs age page 427
df<- read.table("https://www.math.uh.edu/~wwang/Teaching/MATH6357/CH11TA01.txt",header = F)
head(df)
names(df)<- c("Age","BP")
plot(df,main="(a) Scatter Plot")
abline(lm(BP~Age,data=df))
plot(resid(lm(BP~Age,data=df)),xlab = "Age",ylab = "Residual",main = "(b) Residual Plot against X")
abline(h=0)
abs.res=abs(resid(lm(BP~Age,data=df)))
plot(abs.res,xlab = "Age",ylab = "Absolute Residual",main = "(c) Absolute Residual Plot against X")
abs.res.fit <- lm(abs.res~df$Age)
abline(abs.res.fit)
abs.res.fit ### s_hat=-1.5495+.1981723*Age
wts <- 1/fitted(abs.res.fit)^2
final.fit <- lm(BP~Age, data = df, weights = wts)
final.fit
#Ethans part with interaction
# ------------ Creating Confidence Intervals -----------
coeff_int = cbind(coef(df_interaction), confint(df_interaction))
colnames(coeff_int) = c("Estimate", "Lower CI", "Upper CI")
print(coeff_int)
# ------------ Creating Confidence Intervals -----------
coeff_int = cbind(coef(df_best_model), confint(df_best_model))
colnames(coeff_int) = c("Estimate", "Lower CI", "Upper CI")
print(coeff_int)
bonf_conf_int = confint(df_interaction, level = 1 - alpha_a)
# ------------ Bonferroni Confidence Intervals ---------
alpha_a = 0.05/9
print(bonf_conf_int)
bonf_conf_int = confint(df_best_model, level = 1 - alpha_a)
print(bonf_conf_int)
# ------------ Predicting 2022 Season ---------------
df$date = as.Date(df$date, format = "%m/%d/%Y")
df$year = as.integer(format(as.Date(df$date, format = "%m/%d/%Y"), "%Y"))
df.2022 = df[df$year == 2022,]
vars = colnames(df_best)
df.2022_best = df.2022[, vars, drop = FALSE]
predict_2022 = predict(df_best_model, newdata = df.2022_best)
actual_values = df.2022_best$total_run_impact
comparison_df = data.frame(Actual = actual_values, Predicted = predict_2022)
ggplot(comparison_df, aes(x = Actual, y = Predicted)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +  # Add a diagonal line for reference
labs(title = "Actual vs Predicted",
x = "Actual Values",
y = "Predicted Values")
predict_2022.1 = predict(df_interaction, newdata = df.2022_best)
comparison_df.1 = data.frame(Actual = actual_values, Predicted = predict_2022.1)
ggplot(comparison_df.1, aes(x = Actual, y = Predicted)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +  # Add a diagonal line for reference
labs(title = "Actual vs Predicted",
x = "Actual Values",
y = "Predicted Values")
predict_2022.1 = predict(df_interaction, newdata = df.2022_best)
# ------------ Predicting 2022 Season ---------------
df$date = as.Date(df$date, format = "%m/%d/%Y")
# ------------ Predicting 2022 Season ---------------
df$date = as.Date(df$date, format = "%m/%d/%Y")
# ------------ Predicting 2022 Season ---------------
df$date = as.Date(df$date, format = "%m/%d/%Y")
library(tidyverse)
library(ALSM)
library(dplyr)
library(leaps)
library(MASS)
library(ggplot2)
library(lubridate)
df = data.frame(read.csv('umpire_experience.csv'))
df[,7:21] = sapply(df[,7:21], as.numeric) # convert chr to numeric
df$experience = as.factor(df$experience) # create factor with experience
str(df)
df.predictors = df[,7:22]
full.lm = lm((total_run_impact+1) ~., data = df.predictors)
?boxcox
lambda = boxcox(object = full.lm, lambda = seq(-2, 2, 1/10), plotit = FALSE)
which.max(lambda$y)
lambda$x[20]
lm.bc = lm((total_run_impact+1)^-.1~., data = df.predictors) # create model with transform recommended by BC
plot(df.predictors$total_run_impact, lm.bc$residuals) # residuals closer to normal
best_model = regsubsets((total_run_impact+1)^-.1~., data = df.predictors) # find best predictors with reg subsets
best.summary = summary(best_model)
which.max(best.summary$adjr2) # 8 predictors recommended
best.summary$which[8,]
df_best = df.predictors[best.summary$which[8,]] # create df of best performing predictors
# ------------ Creating lm with df_best as dataset -----------
df_best_model = lm((total_run_impact + 1)^(-0.1) ~ ., data = df_best)
summary(df_best_model)
# ------------ Creating Confidence Intervals -----------
coeff_int = cbind(coef(df_best_model), confint(df_best_model))
colnames(coeff_int) = c("Estimate", "Lower CI", "Upper CI")
print(coeff_int)
# ------------ Bonferroni Confidence Intervals ---------
alpha_a = 0.05/9
bonf_conf_int = confint(df_best_model, level = 1 - alpha_a)
print(bonf_conf_int)
# ------------ Predicting 2022 Season ---------------
df$date = as.Date(df$date, format = "%m/%d/%Y")
df$year = as.integer(format(as.Date(df$date, format = "%m/%d/%Y"), "%Y"))
df.2022 = df[df$year == 2022,]
vars = colnames(df_best)
df.2022_best = df.2022[, vars, drop = FALSE]
predict_2022 = predict(df_best_model, newdata = df.2022_best)
actual_values = df.2022_best$total_run_impact
comparison_df = data.frame(Actual = actual_values, Predicted = predict_2022)
ggplot(comparison_df, aes(x = Actual, y = Predicted)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +  # Add a diagonal line for reference
labs(title = "Actual vs Predicted",
x = "Actual Values",
y = "Predicted Values")
predict_2022 = predict(df_interaction, newdata = df.2022_best)
df_interaction <- lm((total_run_impact + 1)^(-0.1) ~ df_best$home_team_runs + df_best$away_team_runs + df_best$pitches_called +
df_best$incorrect_calls + df_best$expected_incorrect_calls + df_best$accuracy_above_expected + df_best$consistency +
df_best$favor_home + df_best$incorrect_calls*df_best$expected_incorrect_calls + df_best$incorrect_calls*df_best$accuracy_above_expected, data = df_best)
predict_2022 = predict(df_interaction, newdata = df.2022_best)
View(df.2022)
View(df.2022)
prediction_2022 = predict(df_interaction, newdata = df.2022_best)
predict_2022 = predict(df_best_model, newdata = df.2022_best)
comparison_df = data.frame(Actual = actual_values, Predicted = prediction_2022)
# ------------ Predicting 2022 Season ---------------
df$date = as.Date(df$date, format = "%m/%d/%Y")
library(tidyverse)
library(ALSM)
library(dplyr)
library(leaps)
library(MASS)
library(ggplot2)
library(lubridate)
df = data.frame(read.csv('umpire_experience.csv'))
df[,7:21] = sapply(df[,7:21], as.numeric) # convert chr to numeric
df$experience = as.factor(df$experience) # create factor with experience
str(df)
df.predictors = df[,7:22]
full.lm = lm((total_run_impact+1) ~., data = df.predictors)
?boxcox
lambda = boxcox(object = full.lm, lambda = seq(-2, 2, 1/10), plotit = FALSE)
which.max(lambda$y)
lambda$x[20]
lm.bc = lm((total_run_impact+1)^-.1~., data = df.predictors) # create model with transform recommended by BC
plot(df.predictors$total_run_impact, lm.bc$residuals) # residuals closer to normal
best_model = regsubsets((total_run_impact+1)^-.1~., data = df.predictors) # find best predictors with reg subsets
best.summary = summary(best_model)
which.max(best.summary$adjr2) # 8 predictors recommended
best.summary$which[8,]
df_best = df.predictors[best.summary$which[8,]] # create df of best performing predictors
# ------------ Creating lm with df_best as dataset -----------
df_best_model = lm((total_run_impact + 1)^(-0.1) ~ ., data = df_best)
summary(df_best_model)
View(df_best)
# ------------ Predicting 2022 Season ---------------
df$date = as.Date(df$date, format = "%m/%d/%Y")
df$year = as.integer(format(as.Date(df$date, format = "%m/%d/%Y"), "%Y"))
df.2022 = df[df$year == 2022,]
vars = colnames(df_best)
df.2022_best = df.2022[, vars, drop = FALSE]
prediction_2022 = predict(df_interaction, newdata = df.2022_best)
df_interaction <- lm((total_run_impact + 1)^(-0.1) ~ df_best$home_team_runs + df_best$away_team_runs + df_best$pitches_called +
df_best$incorrect_calls + df_best$expected_incorrect_calls + df_best$accuracy_above_expected + df_best$consistency +
df_best$favor_home + df_best$incorrect_calls*df_best$expected_incorrect_calls + df_best$incorrect_calls*df_best$accuracy_above_expected, data = df_best)
prediction_2022 = predict(df_interaction, newdata = df.2022_best)
actual_values = df.2022_best$total_run_impact
comparison_df = data.frame(Actual = actual_values, Predicted = prediction_2022)
ggplot(comparison_df, aes(x = Actual, y = Predicted)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +  # Add a diagonal line for reference
labs(title = "Actual vs Predicted",
x = "Actual Values",
y = "Predicted Values")
predict_2022 = predict(df_best_model, newdata = df.2022_best)
actual_values = df.2022_best$total_run_impact
comparison_df = data.frame(Actual = actual_values, Predicted = predict_2022)
ggplot(comparison_df, aes(x = Actual, y = Predicted)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +  # Add a diagonal line for reference
labs(title = "Actual vs Predicted",
x = "Actual Values",
y = "Predicted Values")
library(tidyverse)
library(ALSM)
library(dplyr)
library(leaps)
library(MASS)
library(ggplot2)
library(lubridate)
df = data.frame(read.csv('umpire_experience.csv'))
df[,7:21] = sapply(df[,7:21], as.numeric) # convert chr to numeric
df$experience = as.factor(df$experience) # create factor with experience
str(df)
df.predictors = df[,7:22]
full.lm = lm((total_run_impact+1) ~., data = df.predictors)
?boxcox
lambda = boxcox(object = full.lm, lambda = seq(-2, 2, 1/10), plotit = FALSE)
which.max(lambda$y)
lambda$x[20]
lm.bc = lm((total_run_impact+1)^-.1~., data = df.predictors) # create model with transform recommended by BC
plot(df.predictors$total_run_impact, lm.bc$residuals) # residuals closer to normal
best_model = regsubsets((total_run_impact+1)^-.1~., data = df.predictors) # find best predictors with reg subsets
best.summary = summary(best_model)
which.max(best.summary$adjr2) # 8 predictors recommended
best.summary$which[8,]
df_best = df.predictors[best.summary$which[8,]] # create df of best performing predictors
# ------------ Creating lm with df_best as dataset -----------
df_best_model = lm((total_run_impact + 1)^(-0.1) ~ ., data = df_best)
summary(df_best_model)
# ------------ Creating Confidence Intervals -----------
coeff_int = cbind(coef(df_best_model), confint(df_best_model))
colnames(coeff_int) = c("Estimate", "Lower CI", "Upper CI")
print(coeff_int)
# ------------ Bonferroni Confidence Intervals ---------
alpha_a = 0.05/9
bonf_conf_int = confint(df_best_model, level = 1 - alpha_a)
print(bonf_conf_int)
# ------------ Predicting 2022 Season ---------------
df$date = as.Date(df$date, format = "%m/%d/%Y")
df$year = as.integer(format(as.Date(df$date, format = "%m/%d/%Y"), "%Y"))
df.2022 = df[df$year == 2022,]
vars = colnames(df_best)
df.2022_best = df.2022[, vars, drop = FALSE]
predict_2022 = predict(df_best_model, newdata = df.2022_best)
actual_values = df.2022_best$total_run_impact
comparison_df = data.frame(Actual = actual_values, Predicted = predict_2022)
ggplot(comparison_df, aes(x = Actual, y = Predicted)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +  # Add a diagonal line for reference
labs(title = "Actual vs Predicted",
x = "Actual Values",
y = "Predicted Values")
# ------------ Model Diagnostics ---------------
plot(resid(df_best_model) ~ fitted(df_best_model))
abline(h=0)
qqnorm(resid(df_best_model))
qqline(resid(df_best_model))
#Checking for collinearity
vif(df_best_model)
#Creating a copy of df_best to see correlation better
copy <- df_best
names(copy) <- c('X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'Y')
round(cor(copy))
# ------- check if dropping all interaction terms are appropriate ------
interaction_lm <- lm((total_run_impact + 1)^(-0.1) ~  .^2, data = df_best)
summary(interaction_lm)
###################################################################
# consider four predictors
df<- read.table("https://www.math.uh.edu/~wwang/Teaching/MATH6357/Surgical_Data.txt",header = F)
head(df)
names(df) <- c('x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'y', 'lny')
df <- df[,c(1:3,8,10)]
head(df)
######### check if dropping all 6 interaction terms are appropriate ######
mylm <- lm(lny ~ .^2, data = df)
summary(mylm)
myanov <- anova(mylm)
myanov
(sum(myanov$'Sum Sq'[5:10])/6)/(myanov$'Mean Sq'[11])
1-pf(1.157722,6,43)
######### check if dropping all 6 interaction terms are appropriate: alternative method 7.19 ######
mylm.red <- lm(lny ~ ., data = df)
summary(mylm.red)
rsq_full <- summary(mylm)$r.squared
rsq_red <- summary(mylm.red)$r.squared
(rsq_full-rsq_red)/6/((1-rsq_full)/43)
###### continue without interaction ####
mylm <- lm(lny ~ ., data = df)
summary(mylm)
plot(resid(mylm) ~ fitted(mylm))
abline(h=0)
qqnorm(resid(mylm))
qqline(resid(mylm))
library(ALSM)
vif(mylm)#multicollinearity is not a problem
myanov
intercation_anov <- anova(interaction_lm)
intercation_anov
#H0: All interaction terms are not significant, Ha: At least 1 interaction terms may be significant, alpha : 0.05
(sum(intercation_anov$'Sum Sq'[9:36])/28)/(intercation_anov$'Mean Sq'[37])
1-pf(43.13098,28,18056)
df_interaction.2 <- lm((total_run_impact + 1)^(-0.1) ~ df_best$home_team_runs + df_best$away_team_runs + df_best$pitches_called +
df_best$incorrect_calls + df_best$expected_incorrect_calls + df_best$accuracy_above_expected + df_best$consistency +
df_best$favor_home + df_best$home_team_runs*df_best$away_team_runs + df_best$home_team_runs*df_best$incorrect_calls +
df_best$home_team_runs*df_best$favor_home + df_best$away_team_runs*df_best$expected_incorrect_calls +
df_best$away_team_runs*df_best$favor_home + df_best$pitches_called*df_best$incorrect_calls +
df_best$pitches_called*df_best$consistency + df_best$incorrect_calls*df_best$expected_incorrect_calls +
df_best$incorrect_calls*df_best$accuracy_above_expected + df_best$expected_incorrect_calls*df_best$consistency, data = df_best)
summary(df_interaction.2)
# R^2 of 0.7103 / R^2a = 0.71
anova(df_interaction.2)
plot(resid(df_interaction.2) ~ fitted(df_interaction.2))
abline(h=0)
plot(resid(df_interaction) ~ fitted(df_interaction))
abline(h=0)
df_interaction <- lm((total_run_impact + 1)^(-0.1) ~ df_best$home_team_runs + df_best$away_team_runs + df_best$pitches_called +
df_best$incorrect_calls + df_best$expected_incorrect_calls + df_best$accuracy_above_expected + df_best$consistency +
df_best$favor_home + df_best$incorrect_calls*df_best$expected_incorrect_calls + df_best$incorrect_calls*df_best$accuracy_above_expected, data = df_best)
plot(resid(df_interaction) ~ fitted(df_interaction))
abline(h=0)
#For interaction terms
#Cooks distance
cooks.distance(df_interaction)
plot(cooks.distance(df_interaction),type = "o")
text(cooks.distance(df_interaction), labels=rownames(df_best), cex=0.9, font=2)
title("Cook's Distance")
#14892 appears to be an outlier
cooks.distance(df_interaction.2)
plot(cooks.distance(df_interaction.2),type = "o")
text(cooks.distance(df_interaction.2), labels=rownames(df_best), cex=0.9, font=2)
title("Cook's Distance")
#DFFITS
dffits(df_interaction)
plot(dffits(df_interaction),type = "o")
text(dffits(df_interaction), labels=rownames(df_best), cex=0.9, font=2)
title("DFFITS")
#14892 appears to be an outlier again
dffits(df_interaction.2)
plot(dffits(df_interaction.2),type = "o")
text(dffits(df_interaction.2), labels=rownames(df_best), cex=0.9, font=2)
title("DFFITS")
#DFBETAS
dfbetas(df_interaction)
#DFBETAS
dfbetas(df_interaction)
plot(dfbetas(df_interaction),type = "o")
text(dfbetas(df_interaction), labels=rownames(df_best), cex=0.9, font=2)
title("DFBETAS")
#14892 appears to be an outlier again
dfbetas(df_interaction.2)
plot(dfbetas(df_interaction.2),type = "o")
text(dfbetas(df_interaction.2), labels=rownames(df_best), cex=0.9, font=2)
title("DFBETAS")
plot(resid(df_interaction)~fitted(df_interaction))
abline(h=0)
plot(resid(df_interaction.2)~fitted(df_interaction.2))
abline(h=0)
plot(resid(df_best_model)~fitted(df_best_model))
abline(h=0)
library(tidyverse)
library(ALSM)
library(dplyr)
library(leaps)
library(MASS)
library(ggplot2)
library(lubridate)
df = data.frame(read.csv('umpire_experience.csv'))
df[,7:21] = sapply(df[,7:21], as.numeric) # convert chr to numeric
df$experience = as.factor(df$experience) # create factor with experience
str(df)
df.predictors = df[,7:22]
full.lm = lm((total_run_impact+1) ~., data = df.predictors)
?boxcox
lambda = boxcox(object = full.lm, lambda = seq(-2, 2, 1/10), plotit = FALSE)
which.max(lambda$y)
lambda$x[20]
lm.bc = lm((total_run_impact+1)^-.1~., data = df.predictors) # create model with transform recommended by BC
plot(df.predictors$total_run_impact, lm.bc$residuals) # residuals closer to normal
best_model = regsubsets((total_run_impact+1)^-.1~., data = df.predictors) # find best predictors with reg subsets
best.summary = summary(best_model)
which.max(best.summary$adjr2) # 8 predictors recommended
best.summary$which[8,]
df_best = df.predictors[best.summary$which[8,]] # create df of best performing predictors
# ------------ Creating lm with df_best as dataset -----------
df_best_model = lm((total_run_impact + 1)^(-0.1) ~ ., data = df_best)
summary(df_best_model)
# ------------ Creating Confidence Intervals -----------
coeff_int = cbind(coef(df_best_model), confint(df_best_model))
colnames(coeff_int) = c("Estimate", "Lower CI", "Upper CI")
print(coeff_int)
# ------------ Bonferroni Confidence Intervals ---------
alpha_a = 0.05/9
bonf_conf_int = confint(df_best_model, level = 1 - alpha_a)
print(bonf_conf_int)
# ------------ Predicting 2022 Season ---------------
df$date = as.Date(df$date, format = "%m/%d/%Y")
df$year = as.integer(format(as.Date(df$date, format = "%m/%d/%Y"), "%Y"))
df.2022 = df[df$year == 2022,]
vars = colnames(df_best)
df.2022_best = df.2022[, vars, drop = FALSE]
predict_2022 = predict(df_best_model, newdata = df.2022_best)
actual_values = df.2022_best$total_run_impact
comparison_df = data.frame(Actual = actual_values, Predicted = predict_2022)
ggplot(comparison_df, aes(x = Actual, y = Predicted)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +  # Add a diagonal line for reference
labs(title = "Actual vs Predicted",
x = "Actual Values",
y = "Predicted Values")
# ------------ Model Diagnostics ---------------
plot(resid(df_best_model) ~ fitted(df_best_model))
abline(h=0)
qqnorm(resid(df_best_model))
qqline(resid(df_best_model))
#Checking for collinearity
vif(df_best_model)
#Creating a copy of df_best to see correlation better
copy <- df_best
names(copy) <- c('X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'Y')
round(cor(copy))
# ------- check if dropping all interaction terms are appropriate ------
interaction_lm <- lm((total_run_impact + 1)^(-0.1) ~  .^2, data = df_best)
summary(interaction_lm)
intercation_anov <- anova(interaction_lm)
intercation_anov
#H0: All interaction terms are not significant, Ha: At least 1 interaction terms may be significant, alpha : 0.05
(sum(intercation_anov$'Sum Sq'[9:36])/28)/(intercation_anov$'Mean Sq'[37])
1-pf(43.13098,28,18056)
df_interaction <- lm((total_run_impact + 1)^(-0.1) ~ df_best$home_team_runs + df_best$away_team_runs + df_best$pitches_called +
df_best$incorrect_calls + df_best$expected_incorrect_calls + df_best$accuracy_above_expected + df_best$consistency +
df_best$favor_home + df_best$incorrect_calls*df_best$expected_incorrect_calls + df_best$incorrect_calls*df_best$accuracy_above_expected, data = df_best)
summary(df_interaction)
# R^2 of 0.7094 / R^2a = 0.7092
anova(df_interaction)
plot(resid(df_interaction) ~ fitted(df_interaction))
abline(h=0)
qqnorm(resid(df_interaction))
qqline(resid(df_interaction))
#Cooks distance
cooks.distance(df_interaction)
plot(cooks.distance(df_interaction),type = "o")
text(cooks.distance(df_interaction), labels=rownames(df_best), cex=0.9, font=2)
title("Cook's Distance")
#DFFITS
dffits(df_interaction)
plot(dffits(df_interaction),type = "o")
text(dffits(df_interaction), labels=rownames(df_best), cex=0.9, font=2)
title("DFFITS")
#DFBETAS
dfbetas(df_interaction)
plot(dfbetas(df_interaction),type = "o")
text(dfbetas(df_interaction), labels=rownames(df_best), cex=0.9, font=2)
title("DFBETAS")
# ------------ Model Diagnostics ---------------
plot(resid(df_best_model) ~ fitted(df_best_model))
abline(h=0)
qqnorm(resid(df_best_model))
qqline(resid(df_best_model))
#Checking for collinearity
vif(df_best_model)
#Creating a copy of df_best to see correlation better
copy <- df_best
names(copy) <- c('X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'Y')
round(cor(copy))
# ------- check if dropping all interaction terms are appropriate ------
interaction_lm <- lm((total_run_impact + 1)^(-0.1) ~  .^2, data = df_best)
summary(interaction_lm)
intercation_anov <- anova(interaction_lm)
intercation_anov
#H0: All interaction terms are not significant, Ha: At least 1 interaction terms may be significant, alpha : 0.05
(sum(intercation_anov$'Sum Sq'[9:36])/28)/(intercation_anov$'Mean Sq'[37])
1-pf(43.13098,28,18056)
View(df_best)
View(best_model)
View(df_best)
View(df)
umpire <- read.csv("C:/Users/jesse/OneDrive/Desktop/Grad School/MATH 6357 15443 - Linear Models and Design of Experiments/Project/mlb-umpire-scorecard.csv")
#Convert char to num
umpire$incorrect_calls <- as.numeric(umpire$incorrect_calls)
umpire$pitches_called <- as.numeric(umpire$pitches_called)
umpire$expected_incorrect_calls <- as.numeric(umpire$expected_incorrect_calls)
umpire$correct_calls <- as.numeric(umpire$correct_calls)
umpire$expected_correct_calls <- as.numeric(umpire$expected_correct_calls)
umpire$correct_calls_above_expected <- as.numeric(umpire$correct_calls_above_expected)
umpire$accuracy <- as.numeric(umpire$accuracy)
umpire$expected_accuracy <- as.numeric(umpire$expected_accuracy)
umpire$accuracy_above_expected <- as.numeric(umpire$accuracy_above_expected)
umpire$consistency <- as.numeric(umpire$consistency)
umpire$favor_home <- as.numeric(umpire$favor_home)
umpire$total_run_impact <- as.numeric(umpire$total_run_impact)
#Create a new data frame with out NA's
ump <- data.frame(na.omit(umpire))
#Data with id, date, home, away
ump <- subset(ump, select = -c(id, date, home, away))
#Unique data frames for each umpire with all of their data
umpire_names <- unique(ump$umpire)
for (umpire_name in umpire_names) {
df_name <- paste(umpire_name, ".df", sep = "")
assign(df_name, ump[ump$umpire == umpire_name, ])
}
#Individual umpire data averaged
averages_list <- list()
#Data frame with each all umpires and averaged data
average_umpire_data <- data.frame()
View(`Tony Randazzo.df`)
View(coeff_int)
View(average_umpire_data)
View(averages_list)
View(average_umpire_data)
View(averages_list)
